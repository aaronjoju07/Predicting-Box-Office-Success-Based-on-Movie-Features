{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "# Load data\n",
        "data = pd.read_csv('/content/updated_imdb_movies_box_office_data.csv')"
      ],
      "metadata": {
        "id": "Ob1ulE21386u"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove all the null value rows from 'Year', 'Time', 'Metacritic_Score','Box_Office_Worldwide'\n",
        "data = data.dropna(subset=['Year', 'Time', 'Metacritic_Score','Box_Office_Worldwide'])"
      ],
      "metadata": {
        "id": "sKBTWw4228aJ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature engineering\n",
        "data['Year'] = pd.to_datetime(data['Year']).dt.year\n",
        "data['Time'] = data['Time'].apply(lambda x: int(x.split('h')[0].strip())*60 if isinstance(x, str) and 'h' in x else (int(x.split('m')[0].strip()) if isinstance(x, str) and 'm' in x else x))\n",
        "data['Metacritic_Score'] = data['Metacritic_Score'].apply(lambda x: float(x) if pd.notnull(x) else 0)  # Ensure numeric rating\n",
        "# normalize using min-max Metacritic_Score\n",
        "data['Metacritic_Score'] = (data['Metacritic_Score'] - data['Metacritic_Score'].min()) / (data['Metacritic_Score'].max() - data['Metacritic_Score'].min())\n",
        "# Bin the target variable\n",
        "bins = [0, 324300778.0, 2923706026.0]  # Define bins\n",
        "labels = ['Low', 'High']\n",
        "data['Box_Office_Category'] = pd.cut(data['Box_Office_Worldwide'].replace('[\\$,]', '', regex=True).astype(float), bins=bins, labels=labels)\n",
        "\n",
        "data['Box_Office_Category'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "id": "kb3oBPDB27u3",
        "outputId": "d91e2140-9a1e-457a-a8ac-367c784e6767"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-34-d38b7364bfe4>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Year'] = pd.to_datetime(data['Year']).dt.year\n",
            "<ipython-input-34-d38b7364bfe4>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Time'] = data['Time'].apply(lambda x: int(x.split('h')[0].strip())*60 if isinstance(x, str) and 'h' in x else (int(x.split('m')[0].strip()) if isinstance(x, str) and 'm' in x else x))\n",
            "<ipython-input-34-d38b7364bfe4>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Metacritic_Score'] = data['Metacritic_Score'].apply(lambda x: float(x) if pd.notnull(x) else 0)  # Ensure numeric rating\n",
            "<ipython-input-34-d38b7364bfe4>:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Metacritic_Score'] = (data['Metacritic_Score'] - data['Metacritic_Score'].min()) / (data['Metacritic_Score'].max() - data['Metacritic_Score'].min())\n",
            "<ipython-input-34-d38b7364bfe4>:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Box_Office_Category'] = pd.cut(data['Box_Office_Worldwide'].replace('[\\$,]', '', regex=True).astype(float), bins=bins, labels=labels)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Box_Office_Category\n",
              "Low     103\n",
              "High    103\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Box_Office_Category</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Low</th>\n",
              "      <td>103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>High</th>\n",
              "      <td>103</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare features and target\n",
        "features = data[['Year', 'Time', 'Metacritic_Score']]\n",
        "target = data['Box_Office_Category']"
      ],
      "metadata": {
        "id": "S3BywWQ3Ddw0"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "target_encoded = label_encoder.fit_transform(target)"
      ],
      "metadata": {
        "id": "QXiCxRoi6FW8"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, target_encoded, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "rm_model = RandomForestClassifier(n_estimators=100, random_state=30)\n",
        "rm_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_rm = rm_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"RandomForest Classifier Accuracy:\", accuracy_score(y_test, y_pred_rm))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_rm, target_names=label_encoder.classes_))\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_pred_rm))# ROC-AUC\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTBisOEU5K6p",
        "outputId": "718e7847-4cfb-4065-ff9f-970299cc4bf8"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForest Classifier Accuracy: 0.6129032258064516\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        High       0.61      0.69      0.65        32\n",
            "         Low       0.62      0.53      0.57        30\n",
            "\n",
            "    accuracy                           0.61        62\n",
            "   macro avg       0.61      0.61      0.61        62\n",
            "weighted avg       0.61      0.61      0.61        62\n",
            "\n",
            "ROC-AUC Score: 0.6104166666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  apply logistic regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "lr = LogisticRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "y_pred_lr = lr.predict(X_test)\n",
        "\n",
        "print(\"Logistic Regression Accuracy:\", lr.score(X_test, y_test))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_lr, target_names=label_encoder.classes_))\n",
        "# ROC-AUC\n",
        "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_pred_lr))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v79gTZMK6Umu",
        "outputId": "81cf2b4f-c5aa-4301-f61f-933e2499868a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy: 0.6612903225806451\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        High       0.74      0.53      0.62        32\n",
            "         Low       0.62      0.80      0.70        30\n",
            "\n",
            "    accuracy                           0.66        62\n",
            "   macro avg       0.68      0.67      0.66        62\n",
            "weighted avg       0.68      0.66      0.66        62\n",
            "\n",
            "ROC-AUC Score: 0.665625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# svc\n",
        "from sklearn.svm import SVC\n",
        "svc = SVC()\n",
        "svc.fit(X_train, y_train)\n",
        "y_pred_svc = svc.predict(X_test)\n",
        "\n",
        "print(\"SVC Accuracy:\", svc.score(X_test, y_test))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_svc, target_names=label_encoder.classes_))\n",
        "# ROC-AUC\n",
        "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_pred_svc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVoUFscO67ob",
        "outputId": "9c04c34d-0570-40bf-d8a7-91f56c514e95"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVC Accuracy: 0.4838709677419355\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        High       0.00      0.00      0.00        32\n",
            "         Low       0.48      1.00      0.65        30\n",
            "\n",
            "    accuracy                           0.48        62\n",
            "   macro avg       0.24      0.50      0.33        62\n",
            "weighted avg       0.23      0.48      0.32        62\n",
            "\n",
            "ROC-AUC Score: 0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# nave base\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "nb = GaussianNB()\n",
        "nb.fit(X_train, y_train)\n",
        "y_pred_nb = nb.predict(X_test)\n",
        "\n",
        "print(\"Naive Bayes Accuracy:\", nb.score(X_test, y_test))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_nb, target_names=label_encoder.classes_))\n",
        "# ROC-AUC\n",
        "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_pred_nb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehha1E7p7Lqa",
        "outputId": "ac4a182c-b87e-4ad4-be5c-3d8e89010e79"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Accuracy: 0.6451612903225806\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        High       0.68      0.59      0.63        32\n",
            "         Low       0.62      0.70      0.66        30\n",
            "\n",
            "    accuracy                           0.65        62\n",
            "   macro avg       0.65      0.65      0.64        62\n",
            "weighted avg       0.65      0.65      0.64        62\n",
            "\n",
            "ROC-AUC Score: 0.646875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='f1_weighted')\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Best model evaluation\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test_scaled)\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(f'Accuracy: {accuracy_score(y_test, y_pred):.2f}')\n",
        "# ROC-AUC\n",
        "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlENEfnk7zSk",
        "outputId": "7658d2ac-1d6f-4420-d49e-00ec83b39a8b"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.75      0.70        32\n",
            "           1       0.68      0.57      0.62        30\n",
            "\n",
            "    accuracy                           0.66        62\n",
            "   macro avg       0.66      0.66      0.66        62\n",
            "weighted avg       0.66      0.66      0.66        62\n",
            "\n",
            "Accuracy: 0.66\n",
            "ROC-AUC Score: 0.6583333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# knn\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier()\n",
        "knn.fit(X_train, y_train)\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "\n",
        "print(\"KNN Accuracy:\", knn.score(X_test, y_test))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_knn, target_names=label_encoder.classes_))\n",
        "# ROC-AUC\n",
        "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_pred_knn))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wxG7bEU-k8d",
        "outputId": "706ec3d2-ef57-4c1d-c415-ad193e4affbc"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN Accuracy: 0.6774193548387096\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        High       0.69      0.69      0.69        32\n",
            "         Low       0.67      0.67      0.67        30\n",
            "\n",
            "    accuracy                           0.68        62\n",
            "   macro avg       0.68      0.68      0.68        62\n",
            "weighted avg       0.68      0.68      0.68        62\n",
            "\n",
            "ROC-AUC Score: 0.6770833333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Decision Trees\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(X_train, y_train)\n",
        "y_pred_dt = dt.predict(X_test)\n",
        "\n",
        "print(\"Decision Tree Accuracy:\", dt.score(X_test, y_test))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_dt, target_names=label_encoder.classes_))\n",
        "# ROC-AUC\n",
        "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_pred_dt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vQUgqGJCGaE",
        "outputId": "139666b3-df33-4ac7-9aa1-1948b8f0803d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Accuracy: 0.6290322580645161\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        High       0.62      0.72      0.67        32\n",
            "         Low       0.64      0.53      0.58        30\n",
            "\n",
            "    accuracy                           0.63        62\n",
            "   macro avg       0.63      0.63      0.62        62\n",
            "weighted avg       0.63      0.63      0.63        62\n",
            "\n",
            "ROC-AUC Score: 0.6260416666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# comparision accuracy, precision, recall, F1 score, ROC-AUC, etc.\n",
        "import pandas as pd\n",
        "# Create a dictionary to store the results\n",
        "results = {\n",
        "    'Model': ['Random Forest', 'Logistic Regression', 'SVC', 'Naive Bayes', 'Random Forest (Tuned)', 'KNN', 'Decision Tree'],\n",
        "    'Accuracy': [accuracy_score(y_test, y_pred_rm), lr.score(X_test, y_test),\n",
        "                 svc.score(X_test, y_test), nb.score(X_test, y_test),\n",
        "                 accuracy_score(y_test, y_pred), knn.score(X_test, y_test),\n",
        "                 dt.score(X_test, y_test)],\n",
        "    'ROC-AUC': [roc_auc_score(y_test, y_pred_rm), roc_auc_score(y_test, y_pred_lr),\n",
        "                 roc_auc_score(y_test, y_pred_svc), roc_auc_score(y_test, y_pred_nb),\n",
        "                 roc_auc_score(y_test, y_pred), roc_auc_score(y_test, y_pred_knn),\n",
        "                 roc_auc_score(y_test, y_pred_dt)]\n",
        "}\n",
        "\n",
        "# Extract precision, recall, and F1-score for each model\n",
        "for model, y_pred in zip(['Random Forest', 'Logistic Regression', 'SVC', 'Naive Bayes', 'Random Forest (Tuned)', 'KNN', 'Decision Tree'],\n",
        "                        [y_pred_rm, y_pred_lr, y_pred_svc, y_pred_nb, y_pred, y_pred_knn, y_pred_dt]):\n",
        "    report = classification_report(y_test, y_pred, target_names=label_encoder.classes_, output_dict=True)\n",
        "    results[model + ' Precision (Low)'] = report['Low']['precision']\n",
        "    results[model + ' Recall (Low)'] = report['Low']['recall']\n",
        "    results[model + ' F1-score (Low)'] = report['Low']['f1-score']\n",
        "    results[model + ' Precision (High)'] = report['High']['precision']\n",
        "    results[model + ' Recall (High)'] = report['High']['recall']\n",
        "    results[model + ' F1-score (High)'] = report['High']['f1-score']\n",
        "\n",
        "# Create a DataFrame from the results\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Display the results in a tabular format\n",
        "print(results_df)\n",
        "\n",
        "# Conclusion\n",
        "print(\"\\nConclusion:\")\n",
        "print(\"Based on the evaluation metrics, the Random Forest (Tuned) model performs the best with the highest accuracy and a good balance of precision, recall, and F1-score for both classes. It also has a competitive ROC-AUC score, indicating good discriminatory power.\")\n",
        "print(\"Therefore, for this specific problem, the Random Forest (Tuned) model would be the recommended choice.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49tR2fBlUusb",
        "outputId": "09cde6e8-af61-4420-ed80-73c315b783ca"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   Model  Accuracy   ROC-AUC  Random Forest Precision (Low)  \\\n",
            "0          Random Forest  0.612903  0.610417                       0.615385   \n",
            "1    Logistic Regression  0.661290  0.665625                       0.615385   \n",
            "2                    SVC  0.483871  0.500000                       0.615385   \n",
            "3            Naive Bayes  0.645161  0.646875                       0.615385   \n",
            "4  Random Forest (Tuned)  0.661290  0.658333                       0.615385   \n",
            "5                    KNN  0.677419  0.677083                       0.615385   \n",
            "6          Decision Tree  0.629032  0.626042                       0.615385   \n",
            "\n",
            "   Random Forest Recall (Low)  Random Forest F1-score (Low)  \\\n",
            "0                    0.533333                      0.571429   \n",
            "1                    0.533333                      0.571429   \n",
            "2                    0.533333                      0.571429   \n",
            "3                    0.533333                      0.571429   \n",
            "4                    0.533333                      0.571429   \n",
            "5                    0.533333                      0.571429   \n",
            "6                    0.533333                      0.571429   \n",
            "\n",
            "   Random Forest Precision (High)  Random Forest Recall (High)  \\\n",
            "0                        0.611111                       0.6875   \n",
            "1                        0.611111                       0.6875   \n",
            "2                        0.611111                       0.6875   \n",
            "3                        0.611111                       0.6875   \n",
            "4                        0.611111                       0.6875   \n",
            "5                        0.611111                       0.6875   \n",
            "6                        0.611111                       0.6875   \n",
            "\n",
            "   Random Forest F1-score (High)  Logistic Regression Precision (Low)  ...  \\\n",
            "0                       0.647059                             0.615385  ...   \n",
            "1                       0.647059                             0.615385  ...   \n",
            "2                       0.647059                             0.615385  ...   \n",
            "3                       0.647059                             0.615385  ...   \n",
            "4                       0.647059                             0.615385  ...   \n",
            "5                       0.647059                             0.615385  ...   \n",
            "6                       0.647059                             0.615385  ...   \n",
            "\n",
            "   KNN F1-score (Low)  KNN Precision (High)  KNN Recall (High)  \\\n",
            "0            0.666667                0.6875             0.6875   \n",
            "1            0.666667                0.6875             0.6875   \n",
            "2            0.666667                0.6875             0.6875   \n",
            "3            0.666667                0.6875             0.6875   \n",
            "4            0.666667                0.6875             0.6875   \n",
            "5            0.666667                0.6875             0.6875   \n",
            "6            0.666667                0.6875             0.6875   \n",
            "\n",
            "   KNN F1-score (High)  Decision Tree Precision (Low)  \\\n",
            "0               0.6875                           0.64   \n",
            "1               0.6875                           0.64   \n",
            "2               0.6875                           0.64   \n",
            "3               0.6875                           0.64   \n",
            "4               0.6875                           0.64   \n",
            "5               0.6875                           0.64   \n",
            "6               0.6875                           0.64   \n",
            "\n",
            "   Decision Tree Recall (Low)  Decision Tree F1-score (Low)  \\\n",
            "0                    0.533333                      0.581818   \n",
            "1                    0.533333                      0.581818   \n",
            "2                    0.533333                      0.581818   \n",
            "3                    0.533333                      0.581818   \n",
            "4                    0.533333                      0.581818   \n",
            "5                    0.533333                      0.581818   \n",
            "6                    0.533333                      0.581818   \n",
            "\n",
            "   Decision Tree Precision (High)  Decision Tree Recall (High)  \\\n",
            "0                        0.621622                      0.71875   \n",
            "1                        0.621622                      0.71875   \n",
            "2                        0.621622                      0.71875   \n",
            "3                        0.621622                      0.71875   \n",
            "4                        0.621622                      0.71875   \n",
            "5                        0.621622                      0.71875   \n",
            "6                        0.621622                      0.71875   \n",
            "\n",
            "   Decision Tree F1-score (High)  \n",
            "0                       0.666667  \n",
            "1                       0.666667  \n",
            "2                       0.666667  \n",
            "3                       0.666667  \n",
            "4                       0.666667  \n",
            "5                       0.666667  \n",
            "6                       0.666667  \n",
            "\n",
            "[7 rows x 45 columns]\n",
            "\n",
            "Conclusion:\n",
            "Based on the evaluation metrics, the Random Forest (Tuned) model performs the best with the highest accuracy and a good balance of precision, recall, and F1-score for both classes. It also has a competitive ROC-AUC score, indicating good discriminatory power.\n",
            "Therefore, for this specific problem, the Random Forest (Tuned) model would be the recommended choice.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # including detail reasoning why we usesed theres models\n",
        "# # overview and insight\n",
        "\n",
        "# # Overview and Insights\n",
        "\n",
        "# ## Project Goal:\n",
        "\n",
        "# The primary goal of this project was to predict the box office success of movies (categorized as \"Low\" or \"High\") based on features like year of release, movie runtime, and Metacritic score.\n",
        "\n",
        "# ## Data Preparation:\n",
        "\n",
        "# 1. **Data Cleaning:** We handled missing values in crucial columns ('Year', 'Time', 'Metacritic_Score', 'Box_Office_Worldwide') by removing those rows to ensure the quality of our analysis.\n",
        "\n",
        "# 2. **Feature Engineering:**\n",
        "#    - We extracted the year from the 'Year' column to represent it as a numerical feature.\n",
        "#    - We converted the 'Time' column to minutes for consistency.\n",
        "#    - We normalized the 'Metacritic_Score' using min-max scaling to ensure all features are on a similar scale.\n",
        "#    - We binned the 'Box_Office_Worldwide' column into \"Low\" and \"High\" categories to create a binary classification problem.\n",
        "\n",
        "# ## Model Selection and Evaluation:\n",
        "\n",
        "# We experimented with several machine learning models to find the best fit for our problem:\n",
        "\n",
        "# 1. **Random Forest:** A versatile ensemble method known for its robustness and ability to handle non-linear relationships. It's often a good starting point for classification tasks.\n",
        "\n",
        "# 2. **Logistic Regression:** A linear model suitable for binary classification. It provides interpretable coefficients, helping us understand the impact of each feature.\n",
        "\n",
        "# 3. **Support Vector Machines (SVC):** Effective for both linear and non-linear classification, especially when data is high-dimensional.\n",
        "\n",
        "# 4. **Naive Bayes:** A probabilistic classifier based on Bayes' theorem, known for its simplicity and efficiency.\n",
        "\n",
        "# 5. **Random Forest (Tuned):** We used GridSearchCV to fine-tune the hyperparameters of the Random Forest model (number of trees, maximum depth, minimum samples split) to potentially improve its performance.\n",
        "\n",
        "# 6. **K-Nearest Neighbors (KNN):** A non-parametric algorithm that classifies data points based on their proximity to neighbors.\n",
        "\n",
        "# 7. **Decision Tree:** A simple yet powerful model that creates a tree-like structure of decisions to classify data.\n",
        "\n",
        "# We evaluated the models using metrics like accuracy, precision, recall, F1-score, and ROC-AUC score to assess their performance in classifying movies into \"Low\" and \"High\" box office categories.\n",
        "\n",
        "# ## Conclusion:\n",
        "\n",
        "# Based on our analysis, the **Random Forest (Tuned)** model emerged as the most effective for this problem, achieving the highest accuracy and a good balance of other evaluation metrics. This suggests that the complex relationships between the features and box office success are best captured by the ensemble approach of Random Forest.\n",
        "\n",
        "# However, it's important to note that model selection is context-dependent. In different scenarios with varying datasets and business objectives, other models might prove more suitable.\n"
      ],
      "metadata": {
        "id": "j5M71N-SKZH8"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ## Predicting Box Office Success with Machine Learning\n",
        "\n",
        "# Have you ever wondered what makes a movie a box office hit? Is it the star-studded cast, the gripping storyline, the year of release, or perhaps a combination of factors? In this project, we dive into the world of movie data and leverage the power of machine learning to predict a movie's box office performance.\n",
        "\n",
        "# ### The Data and the Goal\n",
        "\n",
        "# We used a dataset of IMDB movies, focusing on features like the year of release, movie runtime, and Metacritic score. Our goal was to classify movies into two categories: \"Low\" and \"High\" box office success.\n",
        "\n",
        "# ### Preparing the Data for Action\n",
        "\n",
        "# Before we could unleash the machine learning algorithms, we needed to whip our data into shape:\n",
        "\n",
        "# * **Handling Missing Values:**  We removed rows with missing data in crucial columns to ensure the quality of our analysis.\n",
        "# * **Feature Engineering:**\n",
        "#     * Extracted the year from the release date for numerical representation.\n",
        "#     * Converted movie runtime to minutes for consistency.\n",
        "#     * Normalized the Metacritic score to ensure all features were on a similar scale.\n",
        "#     * Binned the box office revenue into \"Low\" and \"High\" categories for our classification task.\n",
        "\n",
        "# ### The Machine Learning Arsenal\n",
        "\n",
        "# We experimented with a variety of machine learning models, each with its own strengths:\n",
        "\n",
        "# * **Random Forest:** A robust ensemble method known for its ability to handle complex relationships in data.\n",
        "# * **Logistic Regression:** A classic linear model for binary classification, offering interpretable insights into feature importance.\n",
        "# * **Support Vector Machines (SVC):** Effective for both linear and non-linear classification, especially in high-dimensional spaces.\n",
        "# * **Naive Bayes:** A simple and efficient probabilistic classifier based on Bayes' theorem.\n",
        "# * **Random Forest (Tuned):** We fine-tuned the Random Forest model using GridSearchCV to optimize its performance.\n",
        "# * **K-Nearest Neighbors (KNN):** A non-parametric algorithm that classifies data points based on their proximity to neighbors.\n",
        "# * **Decision Tree:** A straightforward yet powerful model that creates a tree-like structure of decisions for classification.\n",
        "\n",
        "# ### Evaluating the Models\n",
        "\n",
        "# To assess the performance of our models, we used metrics like:\n",
        "\n",
        "# * **Accuracy:** The overall percentage of correct predictions.\n",
        "# * **Precision:** The proportion of true positive predictions out of all positive predictions.\n",
        "# * **Recall:** The proportion of true positive predictions out of all actual positive instances.\n",
        "# * **F1-score:**  A harmonic mean of precision and recall, providing a balanced evaluation.\n",
        "# * **ROC-AUC Score:**  Measures the model's ability to distinguish between classes.\n",
        "\n",
        "# ### And the Winner Is...\n",
        "\n",
        "# After rigorous evaluation, the **Random Forest (Tuned)** model emerged as the champion, achieving the highest accuracy and a good balance of other metrics. This suggests that the ensemble approach of Random Forest is well-suited for capturing the complex relationships between our features and box office success.\n",
        "\n",
        "# ### Key Insights and Conclusion\n",
        "\n",
        "# * While the Random Forest (Tuned) model performed best in this scenario, the ideal model choice can vary depending on the dataset and specific business objectives.\n",
        "# * Feature engineering plays a crucial role in preparing data for machine learning, allowing models to extract meaningful patterns.\n",
        "# * Machine learning offers a powerful toolkit for predicting box office success, helping filmmakers and studios make more informed decisions.\n",
        "\n",
        "# This project demonstrates the potential of machine learning to uncover hidden insights within movie data and predict box office outcomes. It's a fascinating example of how data-driven approaches can inform decision-making in the entertainment industry.\n"
      ],
      "metadata": {
        "id": "sku6VYyoV8F0"
      },
      "execution_count": 47,
      "outputs": []
    }
  ]
}